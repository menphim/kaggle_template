# Kaggle API åˆ©ç”¨ã‚¬ã‚¤ãƒ‰

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€Kaggle APIã®å…¨æ©Ÿèƒ½ã¨å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ”§ åˆæœŸè¨­å®š

### 1. APIèªè¨¼ã®è¨­å®š
```bash
# 1. Kaggle.com â†’ Account â†’ API â†’ Create New API Token
# 2. kaggle.jsonã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# 3. é©åˆ‡ãªå ´æ‰€ã«é…ç½®
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# 4. èªè¨¼ç¢ºèª
kaggle config view
```

### 2. ç’°å¢ƒæº–å‚™
```bash
# ä»®æƒ³ç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source .venv/bin/activate

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨
python scripts/download_data.py --list
```

## ğŸ† ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æ“ä½œ

### åŸºæœ¬çš„ãªã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æ“ä½œ
```bash
# ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ä¸€è¦§
kaggle competitions list
kaggle competitions list --search "nlp"
kaggle competitions list --category "getting-started"

# ç‰¹å®šã‚³ãƒ³ãƒšã®è©³ç´°
kaggle competitions files titanic
kaggle competitions leaderboard titanic
```

### ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
```bash
# å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle competitions download titanic
python scripts/download_data.py titanic

# ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
kaggle competitions download titanic --file train.csv

# ã‚«ã‚¹ã‚¿ãƒ å‡ºåŠ›å…ˆ
kaggle competitions download titanic -p data/competitions/titanic
python scripts/download_data.py titanic --output data/custom
```

### æå‡ºã¨ã‚¹ã‚³ã‚¢ç¢ºèª
```bash
# æå‡º
kaggle competitions submit submission.csv -c titanic -m "XGBoost baseline model"

# æå‡ºå±¥æ­´
kaggle competitions submissions titanic

# ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰
kaggle competitions leaderboard titanic --show
kaggle competitions leaderboard titanic --download
```

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ“ä½œ

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œç´¢ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
```bash
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œç´¢
kaggle datasets list --search "housing"
kaggle datasets list --file-type "csv"
kaggle datasets list --size-range "1MB:100MB"

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
kaggle datasets list --user "alexisbcook"

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle datasets download zillow/zecon
python scripts/download_data.py --dataset zillow/zecon

# ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
kaggle datasets download zillow/zecon --file State_time_series.csv
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±å–å¾—
```bash
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
kaggle datasets metadata zillow/zecon
kaggle datasets files zillow/zecon

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
kaggle datasets status myusername/mydataset
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆãƒ»æ›´æ–°
```bash
# æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæœŸåŒ–
mkdir my-dataset
cd my-dataset
kaggle datasets init

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç·¨é›†å¾Œã€ä½œæˆ
kaggle datasets create

# æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä½œæˆ
kaggle datasets version -m "Updated with 2024 data"
```

## ğŸ“ ã‚«ãƒ¼ãƒãƒ«/ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ“ä½œ

### ã‚«ãƒ¼ãƒãƒ«æ¤œç´¢ãƒ»å–å¾—
```bash
# ã‚«ãƒ¼ãƒãƒ«æ¤œç´¢
kaggle kernels list --search "tensorflow"
kaggle kernels list --language "python"
kaggle kernels list --user "dansbecker"

# ã‚«ãƒ¼ãƒãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle kernels pull dansbecker/housing-prices-eda -p notebooks/housing-eda

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
kaggle kernels output dansbecker/housing-prices-eda
kaggle kernels files dansbecker/housing-prices-eda
```

### ã‚«ãƒ¼ãƒãƒ«ä½œæˆãƒ»å®Ÿè¡Œ
```bash
# ã‚«ãƒ¼ãƒãƒ«åˆæœŸåŒ–
mkdir my-kernel
cd my-kernel
kaggle kernels init

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨­å®šå¾Œã€å®Ÿè¡Œ
kaggle kernels push

# å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
kaggle kernels status myusername/my-kernel-name
```

## ğŸ¤– ãƒ¢ãƒ‡ãƒ«æ“ä½œ

### ãƒ¢ãƒ‡ãƒ«æ¤œç´¢ãƒ»å–å¾—
```bash
# ãƒ¢ãƒ‡ãƒ«æ¤œç´¢
kaggle models list --search "bert"
kaggle models instances list --search "classification"

# ãƒ¢ãƒ‡ãƒ«è©³ç´°å–å¾—
kaggle models get google/bert

# ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle models instances versions download google/bert/tf2/1
```

### ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ»ç®¡ç†
```bash
# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
kaggle models init -p my-model/

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
kaggle models create

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
kaggle models instances create

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä½œæˆ
kaggle models instances versions create -p my-model/
```

## âš™ï¸ è¨­å®šç®¡ç†

### åŸºæœ¬è¨­å®š
```bash
# ç¾åœ¨ã®è¨­å®šç¢ºèª
kaggle config view

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®š
kaggle config set -n proxy -v http://proxy.company.com:8080

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‘ã‚¹
kaggle config set -n path -v "/custom/download/path"

# è¨­å®šå‰Šé™¤
kaggle config unset -n proxy
```

## ğŸ› ï¸ å®Ÿç”¨çš„ãªä½¿ç”¨ä¾‹

### 1. ã‚³ãƒ³ãƒšå‚åŠ ã®å…¸å‹çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
```bash
# 1. ã‚³ãƒ³ãƒšæ¤œç´¢ãƒ»é¸æŠ
kaggle competitions list --search "tabular"

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python scripts/download_data.py house-prices-advanced-regression-techniques

# 3. æ—¢å­˜ã‚«ãƒ¼ãƒãƒ«å‚è€ƒ
kaggle kernels list --search "house prices" --sort-by "voteCount"
kaggle kernels pull example-user/house-prices-eda -p notebooks/reference

# 4. æå‡º
kaggle competitions submit submission.csv -c house-prices-advanced-regression-techniques -m "Random Forest baseline"

# 5. çµæœç¢ºèª
kaggle competitions submissions house-prices-advanced-regression-techniques
```

### 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ´»ç”¨
```bash
# é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œç´¢
kaggle datasets list --search "real estate"

# è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€æ‹¬å–å¾—
python scripts/download_data.py --dataset username/housing-extra-features
python scripts/download_data.py --dataset username/economic-indicators

# å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆå¾Œã€æ–°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
kaggle datasets init -p data/processed/combined-housing
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç·¨é›†å¾Œ
kaggle datasets create -p data/processed/combined-housing
```

### 3. å­¦ç¿’ãƒ»å‚è€ƒã‚«ãƒ¼ãƒãƒ«æ´»ç”¨
```bash
# ãƒˆãƒƒãƒ—ã‚«ãƒ¼ãƒãƒ«å–å¾—
kaggle kernels list --competition titanic --sort-by "voteCount" | head -5

# è¤‡æ•°ã®å‚è€ƒã‚«ãƒ¼ãƒãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle kernels pull user1/titanic-eda -p notebooks/reference/eda
kaggle kernels pull user2/titanic-feature-engineering -p notebooks/reference/features
kaggle kernels pull user3/titanic-ensemble -p notebooks/reference/models
```

### 4. ãƒãƒƒãƒå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹
```bash
#!/bin/bash
# è¤‡æ•°ã‚³ãƒ³ãƒšã®ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
competitions=("titanic" "house-prices-advanced-regression-techniques" "spaceship-titanic")

for comp in "${competitions[@]}"; do
    echo "Downloading $comp..."
    python scripts/download_data.py "$comp"
done
```

## ğŸ“‹ ã‚³ãƒãƒ³ãƒ‰ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

| æ“ä½œ | ã‚³ãƒãƒ³ãƒ‰ |
|------|----------|
| ã‚³ãƒ³ãƒšä¸€è¦§ | `kaggle competitions list` |
| ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ | `python scripts/download_data.py [comp_name]` |
| æå‡º | `kaggle competitions submit [file] -c [comp] -m "[message]"` |
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œç´¢ | `kaggle datasets list --search "[keyword]"` |
| ã‚«ãƒ¼ãƒãƒ«æ¤œç´¢ | `kaggle kernels list --search "[keyword]"` |
| è¨­å®šç¢ºèª | `kaggle config view` |

## ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºæ³•

```bash
# èªè¨¼ã‚¨ãƒ©ãƒ¼
# â†’ kaggle.jsonã®å ´æ‰€ãƒ»æ¨©é™ç¢ºèª
ls -la ~/.kaggle/kaggle.json
chmod 600 ~/.kaggle/kaggle.json

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼
# â†’ ã‚³ãƒ³ãƒš/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåç¢ºèª
kaggle competitions list --search "[partial_name]"

# æå‡ºã‚¨ãƒ©ãƒ¼
# â†’ ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒ»ã‚µã‚¤ã‚ºç¢ºèª
kaggle competitions files [competition_name]

# APIåˆ¶é™ã‚¨ãƒ©ãƒ¼
# â†’ ä¸€å®šæ™‚é–“å¾…æ©Ÿå¾Œå†å®Ÿè¡Œ
sleep 60 && kaggle competitions list
```

## ğŸ”— å‚è€ƒãƒªãƒ³ã‚¯

- [Kaggle API Documentation](https://github.com/Kaggle/kaggle-api)
- [Kaggle Competitions](https://www.kaggle.com/competitions)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Kaggle Learn](https://www.kaggle.com/learn)